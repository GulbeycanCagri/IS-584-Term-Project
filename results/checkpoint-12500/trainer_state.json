{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.682403433476395,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1072961373390558,
      "grad_norm": 96.8587417602539,
      "learning_rate": 4.824391988555079e-05,
      "loss": 1.7163,
      "step": 500
    },
    {
      "epoch": 0.2145922746781116,
      "grad_norm": 168.7996826171875,
      "learning_rate": 4.645565092989986e-05,
      "loss": 1.838,
      "step": 1000
    },
    {
      "epoch": 0.3218884120171674,
      "grad_norm": 147.00405883789062,
      "learning_rate": 4.466738197424893e-05,
      "loss": 1.8704,
      "step": 1500
    },
    {
      "epoch": 0.4291845493562232,
      "grad_norm": 152.4784698486328,
      "learning_rate": 4.2879113018598e-05,
      "loss": 1.845,
      "step": 2000
    },
    {
      "epoch": 0.5364806866952789,
      "grad_norm": 0.35071390867233276,
      "learning_rate": 4.109084406294707e-05,
      "loss": 1.7798,
      "step": 2500
    },
    {
      "epoch": 0.6437768240343348,
      "grad_norm": 0.10233917087316513,
      "learning_rate": 3.930257510729614e-05,
      "loss": 1.7114,
      "step": 3000
    },
    {
      "epoch": 0.7510729613733905,
      "grad_norm": 24.148189544677734,
      "learning_rate": 3.751788268955651e-05,
      "loss": 1.631,
      "step": 3500
    },
    {
      "epoch": 0.8583690987124464,
      "grad_norm": 0.1913730800151825,
      "learning_rate": 3.5736766809728187e-05,
      "loss": 1.6686,
      "step": 4000
    },
    {
      "epoch": 0.9656652360515021,
      "grad_norm": 0.05109101161360741,
      "learning_rate": 3.394849785407725e-05,
      "loss": 1.4915,
      "step": 4500
    },
    {
      "epoch": 1.0729613733905579,
      "grad_norm": 160.2139129638672,
      "learning_rate": 3.2160228898426327e-05,
      "loss": 1.5658,
      "step": 5000
    },
    {
      "epoch": 1.1802575107296138,
      "grad_norm": 698.7814331054688,
      "learning_rate": 3.0371959942775396e-05,
      "loss": 1.4215,
      "step": 5500
    },
    {
      "epoch": 1.2875536480686696,
      "grad_norm": 0.277258962392807,
      "learning_rate": 2.8587267525035767e-05,
      "loss": 1.245,
      "step": 6000
    },
    {
      "epoch": 1.3948497854077253,
      "grad_norm": 0.11143919080495834,
      "learning_rate": 2.6798998569384837e-05,
      "loss": 1.4679,
      "step": 6500
    },
    {
      "epoch": 1.5021459227467813,
      "grad_norm": 225.2140350341797,
      "learning_rate": 2.5010729613733907e-05,
      "loss": 1.3962,
      "step": 7000
    },
    {
      "epoch": 1.6094420600858368,
      "grad_norm": 780.3433837890625,
      "learning_rate": 2.3226037195994278e-05,
      "loss": 1.3102,
      "step": 7500
    },
    {
      "epoch": 1.7167381974248928,
      "grad_norm": 134.13304138183594,
      "learning_rate": 2.1437768240343348e-05,
      "loss": 1.3969,
      "step": 8000
    },
    {
      "epoch": 1.8240343347639485,
      "grad_norm": 0.15686266124248505,
      "learning_rate": 1.9649499284692418e-05,
      "loss": 1.4955,
      "step": 8500
    },
    {
      "epoch": 1.9313304721030042,
      "grad_norm": 1.371744990348816,
      "learning_rate": 1.7861230329041488e-05,
      "loss": 1.4299,
      "step": 9000
    },
    {
      "epoch": 2.03862660944206,
      "grad_norm": 393.3447570800781,
      "learning_rate": 1.6072961373390558e-05,
      "loss": 1.4378,
      "step": 9500
    },
    {
      "epoch": 2.1459227467811157,
      "grad_norm": 0.4028737246990204,
      "learning_rate": 1.4284692417739628e-05,
      "loss": 1.2362,
      "step": 10000
    },
    {
      "epoch": 2.2532188841201717,
      "grad_norm": 575.95751953125,
      "learning_rate": 1.24964234620887e-05,
      "loss": 1.1707,
      "step": 10500
    },
    {
      "epoch": 2.3605150214592276,
      "grad_norm": 1.017290472984314,
      "learning_rate": 1.071173104434907e-05,
      "loss": 1.2868,
      "step": 11000
    },
    {
      "epoch": 2.467811158798283,
      "grad_norm": 0.31050363183021545,
      "learning_rate": 8.92346208869814e-06,
      "loss": 1.2532,
      "step": 11500
    },
    {
      "epoch": 2.575107296137339,
      "grad_norm": 447.1387023925781,
      "learning_rate": 7.1351931330472105e-06,
      "loss": 1.3232,
      "step": 12000
    },
    {
      "epoch": 2.682403433476395,
      "grad_norm": 0.22552776336669922,
      "learning_rate": 5.3469241773962805e-06,
      "loss": 1.2599,
      "step": 12500
    }
  ],
  "logging_steps": 500,
  "max_steps": 13980,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.72198211584e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
