{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.897151134717528,
  "eval_steps": 500,
  "global_step": 12000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.024142926122646065,
      "grad_norm": 120.87942504882812,
      "learning_rate": 4.977788507967166e-05,
      "loss": 1.216,
      "step": 100
    },
    {
      "epoch": 0.04828585224529213,
      "grad_norm": 0.22802519798278809,
      "learning_rate": 4.95364558184452e-05,
      "loss": 1.6241,
      "step": 200
    },
    {
      "epoch": 0.07242877836793819,
      "grad_norm": 6.268199443817139,
      "learning_rate": 4.9297440849831e-05,
      "loss": 1.622,
      "step": 300
    },
    {
      "epoch": 0.09657170449058426,
      "grad_norm": 1.6307861804962158,
      "learning_rate": 4.905601158860454e-05,
      "loss": 1.7574,
      "step": 400
    },
    {
      "epoch": 0.12071463061323032,
      "grad_norm": 0.016577493399381638,
      "learning_rate": 4.881458232737808e-05,
      "loss": 1.5686,
      "step": 500
    },
    {
      "epoch": 0.14485755673587639,
      "grad_norm": 134.6809539794922,
      "learning_rate": 4.857315306615162e-05,
      "loss": 1.6877,
      "step": 600
    },
    {
      "epoch": 0.16900048285852245,
      "grad_norm": 0.29149872064590454,
      "learning_rate": 4.8331723804925164e-05,
      "loss": 1.7614,
      "step": 700
    },
    {
      "epoch": 0.19314340898116852,
      "grad_norm": 3.3462283611297607,
      "learning_rate": 4.80902945436987e-05,
      "loss": 1.9501,
      "step": 800
    },
    {
      "epoch": 0.2172863351038146,
      "grad_norm": 0.31337982416152954,
      "learning_rate": 4.784886528247224e-05,
      "loss": 1.7193,
      "step": 900
    },
    {
      "epoch": 0.24142926122646063,
      "grad_norm": 0.16660945117473602,
      "learning_rate": 4.7607436021245774e-05,
      "loss": 2.3064,
      "step": 1000
    },
    {
      "epoch": 0.2655721873491067,
      "grad_norm": 108.61538696289062,
      "learning_rate": 4.7366006760019316e-05,
      "loss": 1.658,
      "step": 1100
    },
    {
      "epoch": 0.28971511347175277,
      "grad_norm": 2.225966215133667,
      "learning_rate": 4.712457749879286e-05,
      "loss": 1.978,
      "step": 1200
    },
    {
      "epoch": 0.31385803959439884,
      "grad_norm": 1.3467210531234741,
      "learning_rate": 4.688314823756639e-05,
      "loss": 2.0779,
      "step": 1300
    },
    {
      "epoch": 0.3380009657170449,
      "grad_norm": 0.3956126272678375,
      "learning_rate": 4.664171897633993e-05,
      "loss": 1.4623,
      "step": 1400
    },
    {
      "epoch": 0.362143891839691,
      "grad_norm": 151.88941955566406,
      "learning_rate": 4.6400289715113475e-05,
      "loss": 1.7119,
      "step": 1500
    },
    {
      "epoch": 0.38628681796233705,
      "grad_norm": 124.41545867919922,
      "learning_rate": 4.6158860453887016e-05,
      "loss": 1.9691,
      "step": 1600
    },
    {
      "epoch": 0.4104297440849831,
      "grad_norm": 0.007370843552052975,
      "learning_rate": 4.591743119266055e-05,
      "loss": 1.8135,
      "step": 1700
    },
    {
      "epoch": 0.4345726702076292,
      "grad_norm": 1.7787761688232422,
      "learning_rate": 4.567600193143409e-05,
      "loss": 1.5513,
      "step": 1800
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 7.963350772857666,
      "learning_rate": 4.5434572670207634e-05,
      "loss": 1.8268,
      "step": 1900
    },
    {
      "epoch": 0.48285852245292127,
      "grad_norm": 0.3592122495174408,
      "learning_rate": 4.519314340898117e-05,
      "loss": 1.5377,
      "step": 2000
    },
    {
      "epoch": 0.5070014485755674,
      "grad_norm": 2.5992281436920166,
      "learning_rate": 4.495171414775471e-05,
      "loss": 2.3716,
      "step": 2100
    },
    {
      "epoch": 0.5311443746982134,
      "grad_norm": 0.16133493185043335,
      "learning_rate": 4.4710284886528244e-05,
      "loss": 1.4988,
      "step": 2200
    },
    {
      "epoch": 0.5552873008208595,
      "grad_norm": 0.10321179777383804,
      "learning_rate": 4.4468855625301786e-05,
      "loss": 1.8642,
      "step": 2300
    },
    {
      "epoch": 0.5794302269435055,
      "grad_norm": 1.1042561531066895,
      "learning_rate": 4.422742636407533e-05,
      "loss": 1.8813,
      "step": 2400
    },
    {
      "epoch": 0.6035731530661517,
      "grad_norm": 0.6342862248420715,
      "learning_rate": 4.3988411395461134e-05,
      "loss": 1.8862,
      "step": 2500
    },
    {
      "epoch": 0.6277160791887977,
      "grad_norm": 0.02256864123046398,
      "learning_rate": 4.374698213423467e-05,
      "loss": 1.2697,
      "step": 2600
    },
    {
      "epoch": 0.6518590053114437,
      "grad_norm": 0.7053920030593872,
      "learning_rate": 4.350555287300821e-05,
      "loss": 1.9658,
      "step": 2700
    },
    {
      "epoch": 0.6760019314340898,
      "grad_norm": 0.10822959989309311,
      "learning_rate": 4.326412361178175e-05,
      "loss": 1.7942,
      "step": 2800
    },
    {
      "epoch": 0.7001448575567358,
      "grad_norm": 0.2595077157020569,
      "learning_rate": 4.3022694350555286e-05,
      "loss": 1.4364,
      "step": 2900
    },
    {
      "epoch": 0.724287783679382,
      "grad_norm": 0.43405085802078247,
      "learning_rate": 4.2781265089328834e-05,
      "loss": 1.6136,
      "step": 3000
    },
    {
      "epoch": 0.748430709802028,
      "grad_norm": 1.3339004516601562,
      "learning_rate": 4.253983582810237e-05,
      "loss": 2.06,
      "step": 3100
    },
    {
      "epoch": 0.7725736359246741,
      "grad_norm": 180.509033203125,
      "learning_rate": 4.229840656687591e-05,
      "loss": 1.6422,
      "step": 3200
    },
    {
      "epoch": 0.7967165620473201,
      "grad_norm": 0.06185443326830864,
      "learning_rate": 4.2056977305649445e-05,
      "loss": 1.564,
      "step": 3300
    },
    {
      "epoch": 0.8208594881699662,
      "grad_norm": 0.15647967159748077,
      "learning_rate": 4.1815548044422986e-05,
      "loss": 1.6546,
      "step": 3400
    },
    {
      "epoch": 0.8450024142926122,
      "grad_norm": 209.8981170654297,
      "learning_rate": 4.157411878319653e-05,
      "loss": 1.4646,
      "step": 3500
    },
    {
      "epoch": 0.8691453404152584,
      "grad_norm": 0.07483863085508347,
      "learning_rate": 4.133268952197006e-05,
      "loss": 1.0009,
      "step": 3600
    },
    {
      "epoch": 0.8932882665379044,
      "grad_norm": 0.03283641114830971,
      "learning_rate": 4.1091260260743604e-05,
      "loss": 1.4348,
      "step": 3700
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 409.4168395996094,
      "learning_rate": 4.0854659584741675e-05,
      "loss": 1.4043,
      "step": 3800
    },
    {
      "epoch": 0.9415741187831965,
      "grad_norm": 0.4686865508556366,
      "learning_rate": 4.061323032351521e-05,
      "loss": 1.7288,
      "step": 3900
    },
    {
      "epoch": 0.9657170449058425,
      "grad_norm": 42.643402099609375,
      "learning_rate": 4.037180106228875e-05,
      "loss": 1.1127,
      "step": 4000
    },
    {
      "epoch": 0.9898599710284887,
      "grad_norm": 1257.1644287109375,
      "learning_rate": 4.0130371801062286e-05,
      "loss": 1.2953,
      "step": 4100
    },
    {
      "epoch": 1.0140028971511348,
      "grad_norm": 0.6821104288101196,
      "learning_rate": 3.988894253983583e-05,
      "loss": 1.3129,
      "step": 4200
    },
    {
      "epoch": 1.0381458232737808,
      "grad_norm": 0.10176294296979904,
      "learning_rate": 3.964751327860937e-05,
      "loss": 1.1249,
      "step": 4300
    },
    {
      "epoch": 1.0622887493964268,
      "grad_norm": 0.028277581557631493,
      "learning_rate": 3.940608401738291e-05,
      "loss": 1.4675,
      "step": 4400
    },
    {
      "epoch": 1.0864316755190728,
      "grad_norm": 0.03274276852607727,
      "learning_rate": 3.916465475615645e-05,
      "loss": 1.5031,
      "step": 4500
    },
    {
      "epoch": 1.110574601641719,
      "grad_norm": 0.12901480495929718,
      "learning_rate": 3.8923225494929986e-05,
      "loss": 1.4013,
      "step": 4600
    },
    {
      "epoch": 1.134717527764365,
      "grad_norm": 0.13114230334758759,
      "learning_rate": 3.868179623370353e-05,
      "loss": 1.3369,
      "step": 4700
    },
    {
      "epoch": 1.158860453887011,
      "grad_norm": 1051.466064453125,
      "learning_rate": 3.844036697247706e-05,
      "loss": 1.254,
      "step": 4800
    },
    {
      "epoch": 1.183003380009657,
      "grad_norm": 1630.5123291015625,
      "learning_rate": 3.8198937711250604e-05,
      "loss": 1.027,
      "step": 4900
    },
    {
      "epoch": 1.2071463061323033,
      "grad_norm": 0.28859683871269226,
      "learning_rate": 3.7957508450024145e-05,
      "loss": 1.4052,
      "step": 5000
    },
    {
      "epoch": 1.2312892322549494,
      "grad_norm": 0.19200345873832703,
      "learning_rate": 3.771607918879768e-05,
      "loss": 1.3355,
      "step": 5100
    },
    {
      "epoch": 1.2554321583775954,
      "grad_norm": 0.5953609943389893,
      "learning_rate": 3.747464992757123e-05,
      "loss": 1.0274,
      "step": 5200
    },
    {
      "epoch": 1.2795750845002414,
      "grad_norm": 1.024019718170166,
      "learning_rate": 3.723322066634476e-05,
      "loss": 1.3043,
      "step": 5300
    },
    {
      "epoch": 1.3037180106228874,
      "grad_norm": 0.058991219848394394,
      "learning_rate": 3.6991791405118304e-05,
      "loss": 1.2648,
      "step": 5400
    },
    {
      "epoch": 1.3278609367455336,
      "grad_norm": 0.11256517469882965,
      "learning_rate": 3.6750362143891845e-05,
      "loss": 1.3897,
      "step": 5500
    },
    {
      "epoch": 1.3520038628681796,
      "grad_norm": 0.10735054314136505,
      "learning_rate": 3.6511347175277645e-05,
      "loss": 1.2126,
      "step": 5600
    },
    {
      "epoch": 1.3761467889908257,
      "grad_norm": 0.11880035698413849,
      "learning_rate": 3.626991791405118e-05,
      "loss": 1.2786,
      "step": 5700
    },
    {
      "epoch": 1.4002897151134719,
      "grad_norm": 908.6017456054688,
      "learning_rate": 3.602848865282473e-05,
      "loss": 1.3881,
      "step": 5800
    },
    {
      "epoch": 1.424432641236118,
      "grad_norm": 0.16185106337070465,
      "learning_rate": 3.578705939159826e-05,
      "loss": 1.4793,
      "step": 5900
    },
    {
      "epoch": 1.448575567358764,
      "grad_norm": 0.00566728925332427,
      "learning_rate": 3.5545630130371804e-05,
      "loss": 1.1359,
      "step": 6000
    },
    {
      "epoch": 1.47271849348141,
      "grad_norm": 331.18743896484375,
      "learning_rate": 3.5304200869145345e-05,
      "loss": 1.1224,
      "step": 6100
    },
    {
      "epoch": 1.496861419604056,
      "grad_norm": 0.23082195222377777,
      "learning_rate": 3.506277160791888e-05,
      "loss": 1.1978,
      "step": 6200
    },
    {
      "epoch": 1.521004345726702,
      "grad_norm": 0.2967246472835541,
      "learning_rate": 3.482134234669242e-05,
      "loss": 1.2021,
      "step": 6300
    },
    {
      "epoch": 1.5451472718493482,
      "grad_norm": 4.147815227508545,
      "learning_rate": 3.4579913085465956e-05,
      "loss": 1.188,
      "step": 6400
    },
    {
      "epoch": 1.5692901979719942,
      "grad_norm": 3.070481061935425,
      "learning_rate": 3.43384838242395e-05,
      "loss": 1.333,
      "step": 6500
    },
    {
      "epoch": 1.5934331240946402,
      "grad_norm": 0.0645005851984024,
      "learning_rate": 3.409705456301304e-05,
      "loss": 1.1268,
      "step": 6600
    },
    {
      "epoch": 1.6175760502172865,
      "grad_norm": 0.45092740654945374,
      "learning_rate": 3.3855625301786574e-05,
      "loss": 1.1925,
      "step": 6700
    },
    {
      "epoch": 1.6417189763399325,
      "grad_norm": 2.486884832382202,
      "learning_rate": 3.361419604056012e-05,
      "loss": 1.4369,
      "step": 6800
    },
    {
      "epoch": 1.6658619024625785,
      "grad_norm": 0.027818122878670692,
      "learning_rate": 3.3372766779333656e-05,
      "loss": 1.0549,
      "step": 6900
    },
    {
      "epoch": 1.6900048285852245,
      "grad_norm": 1534.2564697265625,
      "learning_rate": 3.31313375181072e-05,
      "loss": 1.1942,
      "step": 7000
    },
    {
      "epoch": 1.7141477547078705,
      "grad_norm": 210.2902069091797,
      "learning_rate": 3.288990825688074e-05,
      "loss": 1.3194,
      "step": 7100
    },
    {
      "epoch": 1.7382906808305165,
      "grad_norm": 0.012102766893804073,
      "learning_rate": 3.2648478995654274e-05,
      "loss": 1.0649,
      "step": 7200
    },
    {
      "epoch": 1.7624336069531628,
      "grad_norm": 0.0962810069322586,
      "learning_rate": 3.2407049734427815e-05,
      "loss": 1.1609,
      "step": 7300
    },
    {
      "epoch": 1.7865765330758088,
      "grad_norm": 0.036471083760261536,
      "learning_rate": 3.216562047320135e-05,
      "loss": 1.4413,
      "step": 7400
    },
    {
      "epoch": 1.810719459198455,
      "grad_norm": 0.12343759834766388,
      "learning_rate": 3.192419121197489e-05,
      "loss": 1.2781,
      "step": 7500
    },
    {
      "epoch": 1.834862385321101,
      "grad_norm": 188.45431518554688,
      "learning_rate": 3.168276195074843e-05,
      "loss": 1.215,
      "step": 7600
    },
    {
      "epoch": 1.859005311443747,
      "grad_norm": 0.11862732470035553,
      "learning_rate": 3.1441332689521974e-05,
      "loss": 0.9516,
      "step": 7700
    },
    {
      "epoch": 1.883148237566393,
      "grad_norm": 180.60525512695312,
      "learning_rate": 3.1199903428295516e-05,
      "loss": 1.2728,
      "step": 7800
    },
    {
      "epoch": 1.907291163689039,
      "grad_norm": 0.02055330015718937,
      "learning_rate": 3.095847416706905e-05,
      "loss": 0.9875,
      "step": 7900
    },
    {
      "epoch": 1.931434089811685,
      "grad_norm": 0.38127434253692627,
      "learning_rate": 3.071704490584259e-05,
      "loss": 1.2963,
      "step": 8000
    },
    {
      "epoch": 1.955577015934331,
      "grad_norm": 0.15705406665802002,
      "learning_rate": 3.047561564461613e-05,
      "loss": 1.3232,
      "step": 8100
    },
    {
      "epoch": 1.9797199420569773,
      "grad_norm": 0.6243790984153748,
      "learning_rate": 3.023660067600193e-05,
      "loss": 1.0852,
      "step": 8200
    },
    {
      "epoch": 2.0038628681796236,
      "grad_norm": 0.153878316283226,
      "learning_rate": 2.9995171414775474e-05,
      "loss": 1.7484,
      "step": 8300
    },
    {
      "epoch": 2.0280057943022696,
      "grad_norm": 0.07999155670404434,
      "learning_rate": 2.9753742153549012e-05,
      "loss": 1.3047,
      "step": 8400
    },
    {
      "epoch": 2.0521487204249156,
      "grad_norm": 12.76044750213623,
      "learning_rate": 2.9512312892322554e-05,
      "loss": 1.2056,
      "step": 8500
    },
    {
      "epoch": 2.0762916465475616,
      "grad_norm": 0.23997171223163605,
      "learning_rate": 2.927088363109609e-05,
      "loss": 1.2333,
      "step": 8600
    },
    {
      "epoch": 2.1004345726702076,
      "grad_norm": 0.2218904346227646,
      "learning_rate": 2.902945436986963e-05,
      "loss": 0.9075,
      "step": 8700
    },
    {
      "epoch": 2.1245774987928536,
      "grad_norm": 0.0325380377471447,
      "learning_rate": 2.8788025108643168e-05,
      "loss": 0.9676,
      "step": 8800
    },
    {
      "epoch": 2.1487204249154996,
      "grad_norm": 0.012375447899103165,
      "learning_rate": 2.8546595847416706e-05,
      "loss": 0.798,
      "step": 8900
    },
    {
      "epoch": 2.1728633510381457,
      "grad_norm": 1306.5811767578125,
      "learning_rate": 2.8305166586190247e-05,
      "loss": 0.9992,
      "step": 9000
    },
    {
      "epoch": 2.197006277160792,
      "grad_norm": 0.4088199734687805,
      "learning_rate": 2.8063737324963785e-05,
      "loss": 1.166,
      "step": 9100
    },
    {
      "epoch": 2.221149203283438,
      "grad_norm": 0.003502021776512265,
      "learning_rate": 2.782230806373733e-05,
      "loss": 0.7928,
      "step": 9200
    },
    {
      "epoch": 2.245292129406084,
      "grad_norm": 193.3863067626953,
      "learning_rate": 2.7580878802510868e-05,
      "loss": 1.1581,
      "step": 9300
    },
    {
      "epoch": 2.26943505552873,
      "grad_norm": 0.3890197277069092,
      "learning_rate": 2.7339449541284406e-05,
      "loss": 1.1508,
      "step": 9400
    },
    {
      "epoch": 2.293577981651376,
      "grad_norm": 0.21412916481494904,
      "learning_rate": 2.7098020280057944e-05,
      "loss": 0.7607,
      "step": 9500
    },
    {
      "epoch": 2.317720907774022,
      "grad_norm": 0.21805696189403534,
      "learning_rate": 2.6856591018831486e-05,
      "loss": 0.6386,
      "step": 9600
    },
    {
      "epoch": 2.341863833896668,
      "grad_norm": 0.17276117205619812,
      "learning_rate": 2.6615161757605024e-05,
      "loss": 1.2613,
      "step": 9700
    },
    {
      "epoch": 2.366006760019314,
      "grad_norm": 0.23378004133701324,
      "learning_rate": 2.637373249637856e-05,
      "loss": 1.3394,
      "step": 9800
    },
    {
      "epoch": 2.39014968614196,
      "grad_norm": 601.166259765625,
      "learning_rate": 2.61323032351521e-05,
      "loss": 1.0838,
      "step": 9900
    },
    {
      "epoch": 2.4142926122646067,
      "grad_norm": 0.5470669269561768,
      "learning_rate": 2.5890873973925638e-05,
      "loss": 1.1456,
      "step": 10000
    },
    {
      "epoch": 2.4384355383872527,
      "grad_norm": 0.0009913936955854297,
      "learning_rate": 2.564944471269918e-05,
      "loss": 0.8565,
      "step": 10100
    },
    {
      "epoch": 2.4625784645098987,
      "grad_norm": 0.021589545533061028,
      "learning_rate": 2.540801545147272e-05,
      "loss": 1.0766,
      "step": 10200
    },
    {
      "epoch": 2.4867213906325447,
      "grad_norm": 304.7537841796875,
      "learning_rate": 2.5166586190246262e-05,
      "loss": 1.1951,
      "step": 10300
    },
    {
      "epoch": 2.5108643167551907,
      "grad_norm": 235.0138702392578,
      "learning_rate": 2.49251569290198e-05,
      "loss": 1.1858,
      "step": 10400
    },
    {
      "epoch": 2.5350072428778367,
      "grad_norm": 0.11071863025426865,
      "learning_rate": 2.4683727667793338e-05,
      "loss": 1.1205,
      "step": 10500
    },
    {
      "epoch": 2.5591501690004828,
      "grad_norm": 0.021728500723838806,
      "learning_rate": 2.444471269917914e-05,
      "loss": 0.891,
      "step": 10600
    },
    {
      "epoch": 2.5832930951231288,
      "grad_norm": 0.013321230188012123,
      "learning_rate": 2.4203283437952682e-05,
      "loss": 1.3073,
      "step": 10700
    },
    {
      "epoch": 2.607436021245775,
      "grad_norm": 178.76358032226562,
      "learning_rate": 2.396185417672622e-05,
      "loss": 0.829,
      "step": 10800
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.02613198198378086,
      "learning_rate": 2.372042491549976e-05,
      "loss": 0.9927,
      "step": 10900
    },
    {
      "epoch": 2.6557218734910673,
      "grad_norm": 0.5860859155654907,
      "learning_rate": 2.34789956542733e-05,
      "loss": 1.174,
      "step": 11000
    },
    {
      "epoch": 2.6798647996137133,
      "grad_norm": 0.10770928114652634,
      "learning_rate": 2.3237566393046838e-05,
      "loss": 1.1896,
      "step": 11100
    },
    {
      "epoch": 2.7040077257363593,
      "grad_norm": 204.32142639160156,
      "learning_rate": 2.299613713182038e-05,
      "loss": 1.0265,
      "step": 11200
    },
    {
      "epoch": 2.7281506518590053,
      "grad_norm": 0.15995024144649506,
      "learning_rate": 2.2754707870593917e-05,
      "loss": 1.1388,
      "step": 11300
    },
    {
      "epoch": 2.7522935779816513,
      "grad_norm": 0.08325228095054626,
      "learning_rate": 2.2513278609367455e-05,
      "loss": 1.0609,
      "step": 11400
    },
    {
      "epoch": 2.7764365041042973,
      "grad_norm": 0.006924235727638006,
      "learning_rate": 2.2271849348140997e-05,
      "loss": 1.268,
      "step": 11500
    },
    {
      "epoch": 2.8005794302269438,
      "grad_norm": 474.52301025390625,
      "learning_rate": 2.2030420086914535e-05,
      "loss": 1.3273,
      "step": 11600
    },
    {
      "epoch": 2.8247223563495893,
      "grad_norm": 0.12885954976081848,
      "learning_rate": 2.1788990825688073e-05,
      "loss": 1.5191,
      "step": 11700
    },
    {
      "epoch": 2.848865282472236,
      "grad_norm": 0.0011958542745560408,
      "learning_rate": 2.1547561564461614e-05,
      "loss": 0.8289,
      "step": 11800
    },
    {
      "epoch": 2.873008208594882,
      "grad_norm": 0.6847351789474487,
      "learning_rate": 2.1306132303235152e-05,
      "loss": 0.6937,
      "step": 11900
    },
    {
      "epoch": 2.897151134717528,
      "grad_norm": 0.25951504707336426,
      "learning_rate": 2.1064703042008694e-05,
      "loss": 1.4068,
      "step": 12000
    }
  ],
  "logging_steps": 100,
  "max_steps": 20710,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.1451675721728e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
