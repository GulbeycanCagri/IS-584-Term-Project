{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MamxlqH4a7b9",
        "outputId": "258d39a0-b9dd-425f-a3e0-150ea6c956c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWb1V2i6b_g-",
        "outputId": "f489b7dc-0f76-4738-bd5c-73106a0cf5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import wandb\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer,AutoModel,BitsAndBytesConfig,Trainer, TrainingArguments\n",
        "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,roc_auc_score\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "ZIhY2PmwdaIU",
        "outputId": "99fa0eb9-6a59-4b3a-9791-13de5c77cc84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me274028\u001b[0m (\u001b[33me274028-metu-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hF7tSxgVd_4b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rmunSd9cdhRN"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyb1UmLvdjeT",
        "outputId": "149e167e-fc89-43a4-ae97-478c76216345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         paper_id                                               text  \\\n",
            "0  ICLR_2019_1111  The paper proposes GAN regularized by Determin...   \n",
            "1  ICLR_2019_1564  This work proposes a method for both instance ...   \n",
            "2  ICLR_2019_1377  The reviewers highlighted aspects of the work ...   \n",
            "3  ICLR_2019_1179  This paper studies training of the generative ...   \n",
            "4   ICLR_2019_892  The authors propose a GAN-based anomaly detect...   \n",
            "\n",
            "   avg_rating  label  \n",
            "0         5.0      0  \n",
            "1         3.0      0  \n",
            "2         5.0      0  \n",
            "3         5.0      0  \n",
            "4         4.0      0  \n"
          ]
        }
      ],
      "source": [
        "def parse_reviews_to_dataframe(dataset_dir):\n",
        "    records = []\n",
        "\n",
        "    for year_dir in os.listdir(dataset_dir):\n",
        "        year_path = os.path.join(dataset_dir, year_dir)\n",
        "        if not os.path.isdir(year_path):\n",
        "            continue\n",
        "\n",
        "        review_dir = os.path.join(year_path, f\"{year_dir}_review\")\n",
        "        if not os.path.exists(review_dir):\n",
        "            continue\n",
        "\n",
        "        for fname in os.listdir(review_dir):\n",
        "            if not (fname.endswith(\".json\") and \"ICLR\" in fname):\n",
        "                continue\n",
        "\n",
        "            file_path = os.path.join(review_dir, fname)\n",
        "            with open(file_path, \"r\") as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to parse {file_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            paper_id = data.get(\"id\", fname.replace(\".json\", \"\"))\n",
        "            meta_review = data.get(\"metaReview\", \"\")\n",
        "            reviews = data.get(\"reviews\", [])\n",
        "\n",
        "            review_texts = []\n",
        "            rating_scores = []\n",
        "\n",
        "            for review in reviews:\n",
        "                review_text = review.get(\"review\", \"\")\n",
        "                rating_raw = review.get(\"rating\", \"\")\n",
        "                try:\n",
        "                    rating_score = int(rating_raw.split(\":\")[0].strip())\n",
        "                    rating_scores.append(rating_score)\n",
        "                except Exception as e:\n",
        "                    print(f\"Invalid rating. Error is e: {e}\")\n",
        "\n",
        "                review_texts.append(review_text)\n",
        "\n",
        "            #full_text = \" \".join(review_texts + [meta_review]).strip()\n",
        "            avg_rating = sum(rating_scores) / len(rating_scores)\n",
        "            label = 1 if avg_rating >= 6 else 0\n",
        "\n",
        "            records.append({\n",
        "                \"paper_id\": paper_id,\n",
        "                \"text\": meta_review,\n",
        "                \"avg_rating\": avg_rating,\n",
        "                \"label\": label\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# Example usage:\n",
        "df = parse_reviews_to_dataframe(\"dataset/dataset\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l4t1VkZSdtlr"
      },
      "outputs": [],
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "c198a8f73f2240d8a44bc52293575967",
            "0a7cd1b8edfd40ac9635785ae1707970",
            "3436d5bcce384a6ab0f4b5c19261274d",
            "692d69c853674d8e989b67c1568b7d33",
            "c6a779012234434e8fb8702be67f9619",
            "3d5d11b452fd4cdaba8f776691154744",
            "fb847bd5a9d14e88a3b9cfc3cb09c33b",
            "ebf51f5b68f5413ba6318a3f43f919f3",
            "d8025288608e487997a42a141de23078",
            "0a3daa66348441b39efd7e05c8481bd6",
            "40ed2287f59c4723a54600427f80e8f9",
            "cbfc0cba4daf419b82727c5e16ae4b70",
            "2d4ecb1398ba4ae9802f19fcdce11281",
            "91e6ce68efa6439cb30f79791fc87b4e",
            "3e2fb5fff1014f8198b2cd15215bc99d",
            "9564c7a79bdf490284b6f32f7c71c2f3",
            "df843939edc345a59f809b896a564134",
            "33c79499487141078beca57b5e8f288b",
            "74c01d0be67b497dbe07cc85faf27d2d",
            "c1eb37b587754184aeba94a3d5797e82",
            "b15bf1ff0ab8486bbf46de3a29cd3ede",
            "f7bd34c71ff84b878c2c9a4cc7bb09e8",
            "e25114f012624fe8a923f82b5aaecd6b",
            "ae27c5604c344b6d9951a4ca314bb777",
            "8790cbff8996482a8fa030efd4f3e8a6",
            "3f811d9570ef4816955f3bb8c1bb266b",
            "4d9e6334bdec4f0eb33b25cbe8c3bfa1",
            "156854f4744f4e278b072c4c414b4e76",
            "d3a325527ea4405fac53c865d357eecd",
            "3a135245d53943a491051c6bbba8481d",
            "258e7d61b5e544c18eed9731ecea00b7",
            "c86fbd5e89ca47e79c482999758ad1d4",
            "691c3957ce344573901159760bcc9b07",
            "f22a38209c17447dba79260fd9a96077",
            "12a8169f70b9434b95a3d30fba06dfb1",
            "b7e9261136f042f8810653d24dd0352e",
            "3047da9a7c1c49b7b397597c5343c4ff",
            "45e022d452134a22940fe38df7df8788",
            "656a0aeb5166423aa79b4d91ae48931b",
            "f8381cf169b544fcb3802bf6a7025402",
            "8f75091b449b41dd839d4c09e0302931",
            "b7af110b649f463a95c26c49760be5ca",
            "f5c5340c58444171b8108d07fa2f07f8",
            "72c3937aba624da4b3269336225195ef"
          ]
        },
        "id": "cAFiMthpduni",
        "outputId": "9f7266d8-91d3-4b08-842a-acdbfbf4cb0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c198a8f73f2240d8a44bc52293575967"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbfc0cba4daf419b82727c5e16ae4b70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e25114f012624fe8a923f82b5aaecd6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f22a38209c17447dba79260fd9a96077"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, padding_side=\"right\")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YMu9YVNXdwRS"
      },
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=1024):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            item[\"text\"],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(item[\"label\"], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SxU6AZ4EdyKr"
      },
      "outputs": [],
      "source": [
        "train_dataset = ReviewDataset(train_df, tokenizer)\n",
        "val_dataset = ReviewDataset(val_df, tokenizer)\n",
        "test_dataset = ReviewDataset(test_df, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f0eb48c9920049519648ea58a16495a9",
            "7b4ed76c0b93400e88d23f3dd4f94d7e",
            "d13ee43c3f7746a29515a89118959ef0",
            "7ec22215828c44919ec14b310506388b",
            "c73d8d1d479145898cde5fa1b9b70a38",
            "cac7f8e5383c4c8290a343561d26f8dd",
            "5a8df1ab635f4f638a99ff770beb7a5b",
            "2f20e4ab211440cd85a5bfc492f0ab7b",
            "3e453512ecb346769f8b7a3679f4512d",
            "430cc5dc104a40598d5732e8c1fc32a6",
            "69976b2ba160451dbae08dc02fbd559b",
            "f97b73a3bdf54b94adf2309421d524c5",
            "2787b0faa5e747d7949d56ed70ef54dc",
            "4a5ed6b18a0b4f29b1c13a815d1d684c",
            "bfcc1abd4a854748a26e2f78fb05ad4c",
            "ff84f4e278444f4c8511659c8565cc8c",
            "b697d3381a914f8382754158a2f987bc",
            "3a9439db33a84fc29c5be8076f1a406b",
            "d50b783c0e1d4692a968d349c2525d3c",
            "1b6a3811f5794ed491a59b3065a55456",
            "82ef61e72ea14d78876b209a9c438a2b",
            "6622c6c0b3074784b97f1d191e95e9e3"
          ]
        },
        "id": "ac5yW0oZdzvb",
        "outputId": "94dbbb6a-86d7-43a3-8b95-c2efd9ed657e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0eb48c9920049519648ea58a16495a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f97b73a3bdf54b94adf2309421d524c5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JsyvvUdPd3IF"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"binary\", zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "    if logits.shape[1] == 2:\n",
        "        try:\n",
        "            probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)[:, 1].numpy()\n",
        "            auc = roc_auc_score(labels, probs)\n",
        "            metrics[\"auc\"] = auc\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: AUC calculation failed: {e}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def sweep_train():\n",
        "    wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    # === Define target modules ===\n",
        "    target_modules = []\n",
        "    for i in range(12, 22):\n",
        "        target_modules.append(f\"layers.{i}.self_attn.q_proj\")\n",
        "        target_modules.append(f\"layers.{i}.self_attn.v_proj\")\n",
        "\n",
        "    # === LoRA Config with last layers only ===\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=\"SEQ_CLS\",\n",
        "        r=config.r,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        bias=\"none\",\n",
        "        inference_mode=False,\n",
        "        target_modules=target_modules\n",
        "    )\n",
        "\n",
        "    # === Load Quantized Base Model ===\n",
        "    base_model = AutoModel.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    # === Apply LoRA adapters ===\n",
        "    base_model = get_peft_model(base_model, peft_config)\n",
        "    \"\"\"\n",
        "    # === Print LoRA trainable params ===\n",
        "    print(\"Trainable LoRA parameters:\")\n",
        "    for name, param in base_model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(\" -\", name)\n",
        "    \"\"\"\n",
        "\n",
        "    # === Wrap with classification head ===\n",
        "    class QuantizedClassifier(torch.nn.Module):\n",
        "        def __init__(self, base_model, hidden_size=2048, num_labels=2):\n",
        "            super().__init__()\n",
        "            self.base = base_model\n",
        "            self.classifier = torch.nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "            outputs = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            last_hidden = outputs.last_hidden_state\n",
        "            pooled = (last_hidden * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True)\n",
        "            logits = self.classifier(pooled)\n",
        "            loss = None\n",
        "            if labels is not None:\n",
        "                loss_fn = torch.nn.CrossEntropyLoss()\n",
        "                loss = loss_fn(logits, labels)\n",
        "            return SequenceClassifierOutput(\n",
        "                loss=loss,\n",
        "                logits=logits,\n",
        "                hidden_states=outputs.hidden_states if hasattr(outputs, \"hidden_states\") else None,\n",
        "                attentions=outputs.attentions if hasattr(outputs, \"attentions\") else None,\n",
        "            )\n",
        "\n",
        "    model = QuantizedClassifier(base_model, hidden_size=2048, num_labels=2)\n",
        "\n",
        "\n",
        "    # Training setup\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs=10,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=100,\n",
        "        save_steps=500,\n",
        "        save_total_limit=1,\n",
        "        save_strategy=\"epoch\",\n",
        "        fp16=True,\n",
        "        report_to=\"wandb\",\n",
        "        run_name=\"term-project\"\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "    print(\"Test Set Evaluation:\", eval_results)\n",
        "    wandb.log(eval_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2NEBdDf2d6Cs",
        "outputId": "7850299b-cb77-47f1-df79-9e4ae3ce7362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: tvfwq4ot\n",
            "Sweep URL: https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z50c66l3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_161135-z50c66l3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/z50c66l3' target=\"_blank\">dainty-sweep-1</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/z50c66l3' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/z50c66l3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:55, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.780300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.613000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.565000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.501600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.456000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.542400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.542900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.451500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.545600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.532700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.532900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.468700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.511000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.445900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.519400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.532800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.483800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.497900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.463500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.451100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.529100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.425200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.351200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.448600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.479600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.423200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.565100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.374600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.514300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.414200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.477900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.394200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.328600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.528000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.457000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.490200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.393400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.434900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.420600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.543900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.503000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.351800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.372300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.520300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.424300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.467000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.382600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.474500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.451400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.448300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.350500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.387900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.453100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.364400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.333900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.512600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.504300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.462300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.525800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.434100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.401900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.397700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.431500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.355200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.409700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.368800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.455300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.482000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.390300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.333000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.459600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.430600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.477300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.404400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.509100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.453800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.374400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.497700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.437100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.459300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.340600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.391200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.422800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.444200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.446700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.4891979992389679, 'eval_accuracy': 0.859073359073359, 'eval_precision': 0.8243243243243243, 'eval_recall': 0.7218934911242604, 'eval_f1': 0.7697160883280757, 'eval_auc': 0.9103440090876722, 'eval_runtime': 12.2254, 'eval_samples_per_second': 42.371, 'eval_steps_per_second': 10.634, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2581\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2582\u2581\u2582\u2583\u2581\u2582\u2585\u2583\u2582\u2583\u2581\u2582\u2582\u2581\u2583\u2584\u2588\u2581\u2584\u2583\u2583\u2583\u2582\u2581\u2584\u2581\u2581\u2581\u2584\u2584\u2584\u2581\u2585\u2588\u2582\u2583\u2585\u2583\u2584\u2581</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2588\u2587\u2587\u2587\u2587\u2586\u2586\u2586\u2586\u2586\u2586\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2587\u2584\u2586\u2586\u2584\u2585\u2585\u2582\u2584\u2584\u2584\u2585\u2587\u2584\u2583\u2585\u2584\u2586\u2584\u2582\u2584\u2585\u2583\u2584\u2581\u2585\u2586\u2584\u2583\u2584\u2583\u2584\u2584\u2585\u2584\u2585\u2581\u2583\u2584</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.85907</td></tr><tr><td>eval/auc</td><td>0.91034</td></tr><tr><td>eval/f1</td><td>0.76972</td></tr><tr><td>eval/loss</td><td>0.4892</td></tr><tr><td>eval/precision</td><td>0.82432</td></tr><tr><td>eval/recall</td><td>0.72189</td></tr><tr><td>eval/runtime</td><td>12.2254</td></tr><tr><td>eval/samples_per_second</td><td>42.371</td></tr><tr><td>eval/steps_per_second</td><td>10.634</td></tr><tr><td>eval_accuracy</td><td>0.85907</td></tr><tr><td>eval_auc</td><td>0.91034</td></tr><tr><td>eval_f1</td><td>0.76972</td></tr><tr><td>eval_loss</td><td>0.4892</td></tr><tr><td>eval_precision</td><td>0.82432</td></tr><tr><td>eval_recall</td><td>0.72189</td></tr><tr><td>eval_runtime</td><td>12.2254</td></tr><tr><td>eval_samples_per_second</td><td>42.371</td></tr><tr><td>eval_steps_per_second</td><td>10.634</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.01944</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4467</td></tr><tr><td>train_loss</td><td>0.44747</td></tr><tr><td>train_runtime</td><td>1675.558</td></tr><tr><td>train_samples_per_second</td><td>24.72</td></tr><tr><td>train_steps_per_second</td><td>6.183</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dainty-sweep-1</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/z50c66l3' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/z50c66l3</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_161135-z50c66l3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a79wyrup with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_163955-a79wyrup</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/a79wyrup' target=\"_blank\">blooming-sweep-2</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/a79wyrup' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/a79wyrup</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:49, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.574400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.520500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.392300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.502300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.488500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.493200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.396100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.510600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.473200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.425400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.407900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.334600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.498600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.427900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.422900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.537200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.449900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.369300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.466400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.395800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.381400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.462700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.328700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.423800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.447200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.388100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.417800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.416900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.348500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.364900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.476000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.425900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.424300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.467900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.439200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.337000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.364500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.413400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.371200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.335500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.325900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.483800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.469800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.395300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.357600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.390100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.398200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.356400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.412700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.311000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.333000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.399800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.460500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.396600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.414600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.483200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.429200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.412300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.429000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.309900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.317600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.373600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.401800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.4770839512348175, 'eval_accuracy': 0.861003861003861, 'eval_precision': 0.8299319727891157, 'eval_recall': 0.7218934911242604, 'eval_f1': 0.7721518987341772, 'eval_auc': 0.9103100998626676, 'eval_runtime': 12.222, 'eval_samples_per_second': 42.383, 'eval_steps_per_second': 10.637, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2583\u2583\u2582\u2582\u2584\u2581\u2581\u2582\u2585\u2588\u2583\u2584\u2585\u2581\u2582\u2584\u2582\u2582\u2581\u2585\u2581\u2581\u2584\u2587\u2582\u2582\u2582\u2586\u2582\u2587\u2584\u2583\u2582\u2584\u2582\u2583\u2586\u2585\u2584\u2581</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2588\u2588\u2587\u2587\u2587\u2587\u2586\u2586\u2586\u2586\u2585\u2585\u2585\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2583\u2587\u2586\u2583\u2587\u2585\u2585\u2587\u2585\u2584\u2585\u2583\u2584\u2585\u2581\u2584\u2587\u2583\u2584\u2584\u2585\u2582\u2585\u2586\u2584\u2581\u2584\u2586\u2583\u2583\u2583\u2587\u2583\u2585\u2584\u2587\u2584\u2585\u2583</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.861</td></tr><tr><td>eval/auc</td><td>0.91031</td></tr><tr><td>eval/f1</td><td>0.77215</td></tr><tr><td>eval/loss</td><td>0.47708</td></tr><tr><td>eval/precision</td><td>0.82993</td></tr><tr><td>eval/recall</td><td>0.72189</td></tr><tr><td>eval/runtime</td><td>12.222</td></tr><tr><td>eval/samples_per_second</td><td>42.383</td></tr><tr><td>eval/steps_per_second</td><td>10.637</td></tr><tr><td>eval_accuracy</td><td>0.861</td></tr><tr><td>eval_auc</td><td>0.91031</td></tr><tr><td>eval_f1</td><td>0.77215</td></tr><tr><td>eval_loss</td><td>0.47708</td></tr><tr><td>eval_precision</td><td>0.82993</td></tr><tr><td>eval_recall</td><td>0.72189</td></tr><tr><td>eval_runtime</td><td>12.222</td></tr><tr><td>eval_samples_per_second</td><td>42.383</td></tr><tr><td>eval_steps_per_second</td><td>10.637</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.01644</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3967</td></tr><tr><td>train_loss</td><td>0.42897</td></tr><tr><td>train_runtime</td><td>1669.3908</td></tr><tr><td>train_samples_per_second</td><td>24.811</td></tr><tr><td>train_steps_per_second</td><td>6.206</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">blooming-sweep-2</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/a79wyrup' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/a79wyrup</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_163955-a79wyrup/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6c96ypdm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_170815-6c96ypdm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/6c96ypdm' target=\"_blank\">vibrant-sweep-3</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/6c96ypdm' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/6c96ypdm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.645200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.599200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.562700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.465900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.426400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.538400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.449400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.544800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.541300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.380200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.530900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.511100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.476800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.424900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.454600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.390700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.527700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.559400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.482100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.506700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.466600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.463200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.440500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.347500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.516900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.427200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.533700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.427200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.439400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.492700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.581400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.462900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.386100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.484400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.484400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.412500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.487300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.333800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.432700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.515300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.441100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.478200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.401700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.448300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.509900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.352500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.393700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.505700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.434100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.391300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.484500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.432800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.466000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.464800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.335100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.381600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.452700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.332900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.333400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.486100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.510100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.496200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.524600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.432700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.414300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.403200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.360300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.340400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.392100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.456400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.354500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.453000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.366500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.413200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.492300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.425900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.507400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.515100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.474100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.338100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.451000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.444800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.424600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.327100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.311000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.401600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.413700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.458700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.461700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.5193253755569458, 'eval_accuracy': 0.862934362934363, 'eval_precision': 0.831081081081081, 'eval_recall': 0.727810650887574, 'eval_f1': 0.7760252365930599, 'eval_auc': 0.912115766094166, 'eval_runtime': 12.2339, 'eval_samples_per_second': 42.341, 'eval_steps_per_second': 10.626, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2588\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2582\u2582\u2581\u2581\u2584\u2583\u2584\u2583\u2583\u2581\u2581\u2582\u2581\u2583\u2583\u2582\u2582\u2581\u2581\u2581\u2586\u2582\u2583\u2587\u2581\u2581\u2582\u2586\u2582\u2587\u2581\u2583\u2581\u2581\u2583\u2581\u2587\u2581\u2581\u2588</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2588\u2587\u2587\u2587\u2587\u2587\u2586\u2586\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2586\u2583\u2586\u2586\u2584\u2582\u2586\u2584\u2585\u2581\u2585\u2581\u2583\u2587\u2582\u2583\u2585\u2583\u2585\u2583\u2584\u2582\u2584\u2584\u2585\u2583\u2582\u2581\u2584\u2582\u2582\u2584\u2581\u2584\u2584\u2584\u2583\u2583\u2584</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.86293</td></tr><tr><td>eval/auc</td><td>0.91212</td></tr><tr><td>eval/f1</td><td>0.77603</td></tr><tr><td>eval/loss</td><td>0.51933</td></tr><tr><td>eval/precision</td><td>0.83108</td></tr><tr><td>eval/recall</td><td>0.72781</td></tr><tr><td>eval/runtime</td><td>12.2339</td></tr><tr><td>eval/samples_per_second</td><td>42.341</td></tr><tr><td>eval/steps_per_second</td><td>10.626</td></tr><tr><td>eval_accuracy</td><td>0.86293</td></tr><tr><td>eval_auc</td><td>0.91212</td></tr><tr><td>eval_f1</td><td>0.77603</td></tr><tr><td>eval_loss</td><td>0.51933</td></tr><tr><td>eval_precision</td><td>0.83108</td></tr><tr><td>eval_recall</td><td>0.72781</td></tr><tr><td>eval_runtime</td><td>12.2339</td></tr><tr><td>eval_samples_per_second</td><td>42.341</td></tr><tr><td>eval_steps_per_second</td><td>10.626</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.02034</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4617</td></tr><tr><td>train_loss</td><td>0.44807</td></tr><tr><td>train_runtime</td><td>1679.2255</td></tr><tr><td>train_samples_per_second</td><td>24.666</td></tr><tr><td>train_steps_per_second</td><td>6.17</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vibrant-sweep-3</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/6c96ypdm' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/6c96ypdm</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_170815-6c96ypdm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gbwxbplg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_173635-gbwxbplg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/gbwxbplg' target=\"_blank\">major-sweep-4</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/gbwxbplg' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/gbwxbplg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:48, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.693600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.600700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.574800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.521600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.430900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.533500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.533800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.392400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.502800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.488400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.493600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.395900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.403700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.389100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.511500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.472700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.455400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.439900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.424900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.497100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.409100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.336700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.428600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.429800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.469000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.422600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.450500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.369800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.465100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.396500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.380700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.463100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.329600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.405600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.497400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.423700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.386300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.417500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.504500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.364800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.475900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.414600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.426200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.355400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.440900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.426500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.468300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.339300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.414400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.371700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.325300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.456300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.472600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.390300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.381700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.341100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.357600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.413900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.378500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.312600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.427300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.333900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.401100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.457600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.484100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.395900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.413600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.430400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.310700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.311100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.317500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.374700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.47495904564857483, 'eval_accuracy': 0.8687258687258688, 'eval_precision': 0.8435374149659864, 'eval_recall': 0.7337278106508875, 'eval_f1': 0.7848101265822784, 'eval_auc': 0.9106831013377189, 'eval_runtime': 12.147, 'eval_samples_per_second': 42.644, 'eval_steps_per_second': 10.702, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2581\u2582\u2583\u2584\u2582\u2581\u2582\u2583\u2583\u2583\u2583\u2581\u2584\u2581\u2581\u2581\u2583\u2582\u2581\u2584\u2588\u2581\u2581\u2581\u2583\u2583\u2583\u2582\u2585\u2586\u2585\u2582\u2581\u2583\u2585\u2585\u2581\u2583\u2583\u2581</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2587\u2587\u2587\u2587\u2587\u2587\u2586\u2586\u2586\u2586\u2586\u2586\u2585\u2585\u2585\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2586\u2585\u2585\u2582\u2584\u2584\u2584\u2585\u2584\u2583\u2582\u2583\u2585\u2583\u2582\u2583\u2585\u2582\u2584\u2584\u2583\u2582\u2582\u2581\u2582\u2583\u2582\u2583\u2584\u2581\u2583\u2583\u2583\u2584\u2582\u2583\u2581\u2581\u2583</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.86873</td></tr><tr><td>eval/auc</td><td>0.91068</td></tr><tr><td>eval/f1</td><td>0.78481</td></tr><tr><td>eval/loss</td><td>0.47496</td></tr><tr><td>eval/precision</td><td>0.84354</td></tr><tr><td>eval/recall</td><td>0.73373</td></tr><tr><td>eval/runtime</td><td>12.147</td></tr><tr><td>eval/samples_per_second</td><td>42.644</td></tr><tr><td>eval/steps_per_second</td><td>10.702</td></tr><tr><td>eval_accuracy</td><td>0.86873</td></tr><tr><td>eval_auc</td><td>0.91068</td></tr><tr><td>eval_f1</td><td>0.78481</td></tr><tr><td>eval_loss</td><td>0.47496</td></tr><tr><td>eval_precision</td><td>0.84354</td></tr><tr><td>eval_recall</td><td>0.73373</td></tr><tr><td>eval_runtime</td><td>12.147</td></tr><tr><td>eval_samples_per_second</td><td>42.644</td></tr><tr><td>eval_steps_per_second</td><td>10.702</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.01701</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3969</td></tr><tr><td>train_loss</td><td>0.42928</td></tr><tr><td>train_runtime</td><td>1669.119</td></tr><tr><td>train_samples_per_second</td><td>24.815</td></tr><tr><td>train_steps_per_second</td><td>6.207</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">major-sweep-4</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/gbwxbplg' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/gbwxbplg</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_173635-gbwxbplg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4oserjzn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_180446-4oserjzn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/4oserjzn' target=\"_blank\">stellar-sweep-5</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/4oserjzn' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/4oserjzn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:53, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.645300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.599100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.560200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.463800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.428200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.535400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.543500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.542100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.380300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.530900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.492000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.511600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.476800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.422700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.456100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.530600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.558800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.482500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.505800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.469200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.462800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.439800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.345900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.521300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.426900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.428300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.439900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.494100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.431700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.585400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.465100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.488200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.395300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.483300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.412600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.487300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.333400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.435000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.518400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.475200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.403100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.455800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.416500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.513500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.348700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.392500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.502700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.439600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.479700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.488600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.429000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.470900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.337500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.455700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.491400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.508100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.502800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.533800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.423700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.406200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.465900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.347200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.520800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.400700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.358600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.458000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.370300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.413300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.435200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.507800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.468600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.346100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.455400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.441800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.308200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.329700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.400400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.417400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.451700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.467100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.5205214619636536, 'eval_accuracy': 0.8687258687258688, 'eval_precision': 0.8389261744966443, 'eval_recall': 0.7396449704142012, 'eval_f1': 0.7861635220125787, 'eval_auc': 0.9119546972753937, 'eval_runtime': 12.2488, 'eval_samples_per_second': 42.29, 'eval_steps_per_second': 10.613, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2582\u2581\u2583\u2581\u2581\u2582\u2582\u2583\u2582\u2582\u2584\u2582\u2581\u2583\u2583\u2584\u2581\u2584\u2581\u2581\u2585\u2581\u2584\u2582\u2582\u2583\u2586\u2584\u2581\u2582\u2582\u2586\u2585\u2581\u2582\u2588\u2581\u2585\u2581\u2581</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2587\u2587\u2587\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2585\u2585\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2586\u2584\u2587\u2582\u2585\u2586\u2585\u2584\u2581\u2583\u2584\u2584\u2588\u2582\u2583\u2583\u2581\u2583\u2584\u2587\u2581\u2583\u2584\u2585\u2584\u2585\u2581\u2582\u2584\u2585\u2586\u2584\u2583\u2583\u2584\u2586\u2586\u2581\u2583</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.86873</td></tr><tr><td>eval/auc</td><td>0.91195</td></tr><tr><td>eval/f1</td><td>0.78616</td></tr><tr><td>eval/loss</td><td>0.52052</td></tr><tr><td>eval/precision</td><td>0.83893</td></tr><tr><td>eval/recall</td><td>0.73964</td></tr><tr><td>eval/runtime</td><td>12.2488</td></tr><tr><td>eval/samples_per_second</td><td>42.29</td></tr><tr><td>eval/steps_per_second</td><td>10.613</td></tr><tr><td>eval_accuracy</td><td>0.86873</td></tr><tr><td>eval_auc</td><td>0.91195</td></tr><tr><td>eval_f1</td><td>0.78616</td></tr><tr><td>eval_loss</td><td>0.52052</td></tr><tr><td>eval_precision</td><td>0.83893</td></tr><tr><td>eval_recall</td><td>0.73964</td></tr><tr><td>eval_runtime</td><td>12.2488</td></tr><tr><td>eval_samples_per_second</td><td>42.29</td></tr><tr><td>eval_steps_per_second</td><td>10.613</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.01648</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4671</td></tr><tr><td>train_loss</td><td>0.44941</td></tr><tr><td>train_runtime</td><td>1674.1255</td></tr><tr><td>train_samples_per_second</td><td>24.741</td></tr><tr><td>train_steps_per_second</td><td>6.188</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stellar-sweep-5</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/4oserjzn' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/4oserjzn</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_180446-4oserjzn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2pv10olk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlora_dropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_183301-2pv10olk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/2pv10olk' target=\"_blank\">solar-sweep-6</a></strong> to <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/sweeps/tvfwq4ot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/2pv10olk' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/2pv10olk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-16-3601937503.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10360' max='10360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10360/10360 27:48, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.693500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.574400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.539300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.445900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.392300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.502300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.488500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.493100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.474900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.396100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.510700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.473200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.494400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.455500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.425400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.334600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.498500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.428000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.428300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.422900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.537200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.449800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.369300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.466300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.381500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.462800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.328700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.423900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.447200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.388000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.417900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.417000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.504000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.348500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.364800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.476000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.426000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.424400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.468000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.439200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.337100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.364500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.413200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.335500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.325900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.483900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.422600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.469800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.395200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.357600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.390200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.380500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.398200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.340100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.356400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.412800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.498200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.311100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.333100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.399900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.460600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.414700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.483200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.429100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.412400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.429000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.317600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.373500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.401900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.431000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.396700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation: {'eval_loss': 0.47707635164260864, 'eval_accuracy': 0.861003861003861, 'eval_precision': 0.8299319727891157, 'eval_recall': 0.7218934911242604, 'eval_f1': 0.7721518987341772, 'eval_auc': 0.9102931452501652, 'eval_runtime': 12.2333, 'eval_samples_per_second': 42.343, 'eval_steps_per_second': 10.627, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>\u2581</td></tr><tr><td>eval/accuracy</td><td>\u2581</td></tr><tr><td>eval/auc</td><td>\u2581</td></tr><tr><td>eval/f1</td><td>\u2581</td></tr><tr><td>eval/loss</td><td>\u2581</td></tr><tr><td>eval/precision</td><td>\u2581</td></tr><tr><td>eval/recall</td><td>\u2581</td></tr><tr><td>eval/runtime</td><td>\u2581</td></tr><tr><td>eval/samples_per_second</td><td>\u2581</td></tr><tr><td>eval/steps_per_second</td><td>\u2581</td></tr><tr><td>eval_accuracy</td><td>\u2581</td></tr><tr><td>eval_auc</td><td>\u2581</td></tr><tr><td>eval_f1</td><td>\u2581</td></tr><tr><td>eval_loss</td><td>\u2581</td></tr><tr><td>eval_precision</td><td>\u2581</td></tr><tr><td>eval_recall</td><td>\u2581</td></tr><tr><td>eval_runtime</td><td>\u2581</td></tr><tr><td>eval_samples_per_second</td><td>\u2581</td></tr><tr><td>eval_steps_per_second</td><td>\u2581</td></tr><tr><td>train/epoch</td><td>\u2581\u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/global_step</td><td>\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588</td></tr><tr><td>train/grad_norm</td><td>\u2584\u2582\u2582\u2585\u2583\u2581\u2585\u2582\u2584\u2584\u2581\u2581\u2582\u2584\u2584\u2581\u2581\u2581\u2586\u2585\u2584\u2584\u2584\u2584\u2584\u2583\u2584\u2583\u2586\u2586\u2588\u2583\u2587\u2584\u2582\u2583\u2586\u2586\u2584\u2581</td></tr><tr><td>train/learning_rate</td><td>\u2588\u2588\u2588\u2588\u2588\u2587\u2587\u2587\u2587\u2587\u2586\u2586\u2586\u2586\u2586\u2585\u2585\u2585\u2585\u2585\u2585\u2585\u2584\u2584\u2584\u2584\u2584\u2583\u2583\u2583\u2583\u2583\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581</td></tr><tr><td>train/loss</td><td>\u2588\u2586\u2586\u2586\u2585\u2585\u2586\u2584\u2584\u2582\u2583\u2581\u2584\u2584\u2585\u2585\u2584\u2583\u2585\u2581\u2584\u2583\u2586\u2582\u2584\u2583\u2581\u2585\u2584\u2585\u2583\u2585\u2583\u2581\u2585\u2583\u2584\u2581\u2582\u2584</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval/accuracy</td><td>0.861</td></tr><tr><td>eval/auc</td><td>0.91029</td></tr><tr><td>eval/f1</td><td>0.77215</td></tr><tr><td>eval/loss</td><td>0.47708</td></tr><tr><td>eval/precision</td><td>0.82993</td></tr><tr><td>eval/recall</td><td>0.72189</td></tr><tr><td>eval/runtime</td><td>12.2333</td></tr><tr><td>eval/samples_per_second</td><td>42.343</td></tr><tr><td>eval/steps_per_second</td><td>10.627</td></tr><tr><td>eval_accuracy</td><td>0.861</td></tr><tr><td>eval_auc</td><td>0.91029</td></tr><tr><td>eval_f1</td><td>0.77215</td></tr><tr><td>eval_loss</td><td>0.47708</td></tr><tr><td>eval_precision</td><td>0.82993</td></tr><tr><td>eval_recall</td><td>0.72189</td></tr><tr><td>eval_runtime</td><td>12.2333</td></tr><tr><td>eval_samples_per_second</td><td>42.343</td></tr><tr><td>eval_steps_per_second</td><td>10.627</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>10360</td></tr><tr><td>train/grad_norm</td><td>0.01642</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3967</td></tr><tr><td>train_loss</td><td>0.42898</td></tr><tr><td>train_runtime</td><td>1668.9483</td></tr><tr><td>train_samples_per_second</td><td>24.818</td></tr><tr><td>train_steps_per_second</td><td>6.208</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">solar-sweep-6</strong> at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/2pv10olk' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora/runs/2pv10olk</a><br> View project at: <a href='https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora' target=\"_blank\">https://wandb.ai/e274028-metu-middle-east-technical-university/tinyllama-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250623_183301-2pv10olk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"grid\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"eval/accuracy\",\n",
        "        \"goal\": \"maximize\"\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\": {\"values\": [2e-5, 3e-5]},\n",
        "        \"r\": {\"values\": [4, 8]},\n",
        "        \"lora_dropout\": {\"values\": [0.05, 0.1]}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"tinyllama-lora\")\n",
        "wandb.agent(sweep_id, function=sweep_train, count=6)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}